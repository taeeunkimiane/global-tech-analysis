# app.py - ê¸€ë¡œë²Œ ê¸°ìˆ  ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ (ë…ë¦½í˜• ë²„ì „)
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import json
from collections import Counter, defaultdict
import time
import requests

# ì„ íƒì  import (ì—†ì–´ë„ ì‘ë™í•˜ë„ë¡)
try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except ImportError:
    TEXTBLOB_AVAILABLE = False

try:
    import networkx as nx
    NETWORKX_AVAILABLE = True
except ImportError:
    NETWORKX_AVAILABLE = False

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê¸€ë¡œë²Œ ê¸°ìˆ  ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2E86AB;
        margin-bottom: 1rem;
        border-bottom: 2px solid #E8F4FD;
        padding-bottom: 0.5rem;
    }
    .metric-card {
        background: linear-gradient(45deg, #f0f2f6, #ffffff);
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #667eea;
        margin: 0.5rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        transition: transform 0.3s ease;
    }
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
    }
    .tech-category {
        background: linear-gradient(135deg, #667eea, #764ba2);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        margin: 0.2rem;
        display: inline-block;
        font-size: 0.9rem;
        font-weight: bold;
    }
    .country-flag {
        font-size: 1.5rem;
        margin-right: 0.5rem;
    }
    .insight-box {
        background: linear-gradient(45deg, #e3f2fd, #f3e5f5);
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #2196f3;
        margin: 1rem 0;
    }
    .data-source {
        font-size: 0.8rem;
        color: #666;
        text-align: right;
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# ê¸°ìˆ  ì¹´í…Œê³ ë¦¬ ë° êµ­ê°€ ì •ì˜
TECH_CATEGORIES = {
    "í•˜ë“œì›¨ì–´ í˜ì‹ ": {
        "keywords": ["ìŠ¤í•€íŠ¸ë¡œë‹‰ìŠ¤", "ë§ˆê·¸ë…¸ë‹‰ìŠ¤", "ì–‘ìì»´í“¨íŒ…", "ë°˜ë„ì²´", "ì¹©ì…‹", "í”„ë¡œì„¸ì„œ"],
        "color": "#FF6B6B"
    },
    "AI/ML": {
        "keywords": ["ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "GPT", "LLM", "ë² ì´ì§€ì•ˆ"],
        "color": "#4ECDC4"
    },
    "ë³´ì•ˆ/í•´í‚¹": {
        "keywords": ["ì‚¬ì´ë²„ë³´ì•ˆ", "í•´í‚¹", "ë°ì´í„°ë³´ì•ˆ", "í”„ë¼ì´ë²„ì‹œ", "ì•”í˜¸í™”"],
        "color": "#45B7D1"
    },
    "ë²•ë¥ /ê·œì œ": {
        "keywords": ["AIë²•", "ë°ì´í„°ë³´í˜¸", "GDPR", "ê·œì œ", "ì •ì±…", "ê±°ë²„ë„ŒìŠ¤"],
        "color": "#96CEB4"
    },
    "ììœ¨ì‹œìŠ¤í…œ": {
        "keywords": ["ììœ¨ì£¼í–‰", "ë¡œë´‡", "ë“œë¡ ", "IoT", "ìŠ¤ë§ˆíŠ¸ì‹œí‹°"],
        "color": "#FFEAA7"
    }
}

COUNTRIES = {
    "ë¯¸êµ­": "ğŸ‡ºğŸ‡¸",
    "ì¤‘êµ­": "ğŸ‡¨ğŸ‡³", 
    "ì¼ë³¸": "ğŸ‡¯ğŸ‡µ",
    "ë…ì¼": "ğŸ‡©ğŸ‡ª",
    "ì˜êµ­": "ğŸ‡¬ğŸ‡§",
    "í”„ë‘ìŠ¤": "ğŸ‡«ğŸ‡·",
    "í•œêµ­": "ğŸ‡°ğŸ‡·",
    "ì´ìŠ¤ë¼ì—˜": "ğŸ‡®ğŸ‡±",
    "ì‹±ê°€í¬ë¥´": "ğŸ‡¸ğŸ‡¬",
    "ìºë‚˜ë‹¤": "ğŸ‡¨ğŸ‡¦"
}

class TechNewsAnalyzer:
    """ê°„ì†Œí™”ëœ ê¸°ìˆ  ë‰´ìŠ¤ ë¶„ì„ê¸°"""
    
    def __init__(self, articles):
        self.articles = articles
        self.df = pd.DataFrame(articles) if articles else pd.DataFrame()
        if not self.df.empty:
            self.df['date'] = pd.to_datetime(self.df['date'])
    
    def analyze_sentiment(self, text):
        """ê°ì • ë¶„ì„ (TextBlob ì‚¬ìš© ë˜ëŠ” ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        if TEXTBLOB_AVAILABLE:
            try:
                blob = TextBlob(text)
                return blob.sentiment.polarity
            except:
                pass
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„
        positive_words = ['ì„±ê³µ', 'í˜ì‹ ', 'ê°œë°œ', 'ë°œì „', 'í–¥ìƒ', 'breakthrough', 'success', 'innovation']
        negative_words = ['ê³µê²©', 'ìœ„í—˜', 'ë¬¸ì œ', 'ì‹¤íŒ¨', 'ìš°ë ¤', 'attack', 'threat', 'problem', 'failure']
        
        text_lower = text.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)
        
        if pos_count > neg_count:
            return 0.3
        elif neg_count > pos_count:
            return -0.3
        else:
            return 0.0
    
    def categorize_article(self, article):
        """ê¸°ì‚¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        text = f"{article.get('title', '')} {article.get('content', '')}".lower()
        
        category_scores = {}
        for category, info in TECH_CATEGORIES.items():
            score = sum(1 for keyword in info['keywords'] if keyword.lower() in text)
            category_scores[category] = score
        
        if max(category_scores.values()) > 0:
            return max(category_scores, key=category_scores.get)
        return "ê¸°íƒ€"
    
    def detect_emerging_trends(self, window_days=7):
        """ì‹ í¥ íŠ¸ë Œë“œ ê°ì§€"""
        if self.df.empty:
            return {}
        
        recent_date = self.df['date'].max()
        cutoff_date = recent_date - timedelta(days=window_days)
        
        recent_articles = self.df[self.df['date'] >= cutoff_date]
        older_articles = self.df[self.df['date'] < cutoff_date]
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        recent_text = ' '.join(recent_articles['title'].fillna('') + ' ' + recent_articles['content'].fillna(''))
        older_text = ' '.join(older_articles['title'].fillna('') + ' ' + older_articles['content'].fillna(''))
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)
        keywords = ['AI', 'blockchain', 'quantum', 'autonomous', 'cybersecurity', 'regulation']
        trending = {}
        
        for keyword in keywords:
            recent_count = recent_text.lower().count(keyword.lower())
            older_count = older_text.lower().count(keyword.lower()) or 1
            
            if recent_count >= 2:
                trend_score = recent_count / older_count
                if trend_score > 1.5:
                    trending[keyword] = {
                        'recent_frequency': recent_count,
                        'older_frequency': older_count,
                        'trend_score': trend_score
                    }
        
        return dict(sorted(trending.items(), key=lambda x: x[1]['trend_score'], reverse=True))
    
    def analyze_country_tech_focus(self):
        """êµ­ê°€ë³„ ê¸°ìˆ  ì§‘ì¤‘ë„ ë¶„ì„"""
        if self.df.empty:
            return {}
        
        country_tech = defaultdict(lambda: defaultdict(int))
        
        for _, row in self.df.iterrows():
            country_tech[row['country']][row['category']] += 1
        
        # ì •ê·œí™”
        country_tech_normalized = {}
        for country, tech_counts in country_tech.items():
            total_articles = sum(tech_counts.values())
            if total_articles > 0:
                country_tech_normalized[country] = {
                    tech: count / total_articles
                    for tech, count in tech_counts.items()
                }
        
        return country_tech_normalized
    
    def generate_insights_report(self):
        """ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        if self.df.empty:
            return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        total_articles = len(self.df)
        date_range = f"{self.df['date'].min().strftime('%Y-%m-%d')} ~ {self.df['date'].max().strftime('%Y-%m-%d')}"
        
        report = []
        report.append(f"ğŸ“Š **ë¶„ì„ ê¸°ê°„**: {date_range}")
        report.append(f"ğŸ“° **ì´ ê¸°ì‚¬ ìˆ˜**: {total_articles:,}ê°œ")
        report.append("")
        
        # êµ­ê°€ë³„ í™œë™ë„
        country_counts = self.df['country'].value_counts()
        report.append("ğŸŒ **êµ­ê°€ë³„ ê¸°ìˆ  ì´ìŠˆ í™œë™ë„**")
        for country, count in country_counts.head(5).items():
            percentage = (count / total_articles) * 100
            flag = COUNTRIES.get(country, "ğŸ³ï¸")
            report.append(f"- {flag} {country}: {count}ê°œ ({percentage:.1f}%)")
        report.append("")
        
        # ê¸°ìˆ  ë¶„ì•¼ë³„ ê´€ì‹¬ë„
        category_counts = self.df['category'].value_counts()
        report.append("ğŸ”¬ **ê¸°ìˆ  ë¶„ì•¼ë³„ ê´€ì‹¬ë„**")
        for category, count in category_counts.head(5).items():
            percentage = (count / total_articles) * 100
            report.append(f"- {category}: {count}ê°œ ({percentage:.1f}%)")
        report.append("")
        
        # í‰ê·  ê°ì •
        avg_sentiment = self.df['sentiment'].mean()
        sentiment_label = "ê¸ì •ì " if avg_sentiment > 0.1 else "ë¶€ì •ì " if avg_sentiment < -0.1 else "ì¤‘ë¦½ì "
        report.append("ğŸ­ **ì „ë°˜ì  ì—¬ë¡ **")
        report.append(f"- í‰ê·  ê°ì • ì ìˆ˜: {avg_sentiment:.3f} ({sentiment_label})")
        
        return "\n".join(report)

@st.cache_data
def load_sample_data():
    """í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    countries = list(COUNTRIES.keys())
    categories = list(TECH_CATEGORIES.keys())
    
    # ì‹¤ì œì ì¸ ìƒ˜í”Œ ê¸°ì‚¬ ë°ì´í„°
    sample_articles = [
        {
            'title': 'ë¯¸êµ­, ì°¨ì„¸ëŒ€ ìŠ¤í•€íŠ¸ë¡œë‹‰ìŠ¤ ì¹© ê°œë°œ ì„±ê³µ',
            'content': 'ë¯¸êµ­ ì—°êµ¬ì§„ì´ ì „ìì˜ ìŠ¤í•€ì„ ì´ìš©í•œ í˜ì‹ ì ì¸ ì»´í“¨íŒ… ê¸°ìˆ ì„ ê°œë°œí–ˆë‹¤. ì´ ê¸°ìˆ ì€ ê¸°ì¡´ ë°˜ë„ì²´ë³´ë‹¤ 100ë°° ë¹ ë¥¸ ì—°ì‚° ì†ë„ì™€ 1/10 ìˆ˜ì¤€ì˜ ì „ë ¥ ì†Œë¹„ë¥¼ ì‹¤í˜„í•œë‹¤.',
            'country': 'ë¯¸êµ­',
            'category': 'í•˜ë“œì›¨ì–´ í˜ì‹ ',
            'date': '2025-07-03',
            'sentiment': 0.752,
            'source': 'MIT Technology Review',
            'url': 'https://example.com/article/1'
        },
        {
            'title': 'ì¤‘êµ­ AI ê¸°ì—…, ë¹„ëª¨ìˆ˜ ë² ì´ì§€ì•ˆ ëª¨ë¸ ê°œë°œ',
            'content': 'ì¤‘êµ­ AI ê¸°ì—…ì´ ë¶ˆí™•ì‹¤ì„±ì„ ì •ëŸ‰ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ë¹„ëª¨ìˆ˜ ë² ì´ì§€ì•ˆ AI ëª¨ë¸ì„ ê°œë°œí–ˆë‹¤ê³  ë°œí‘œí–ˆë‹¤.',
            'country': 'ì¤‘êµ­',
            'category': 'AI/ML',
            'date': '2025-07-02',
            'sentiment': 0.634,
            'source': 'Tech in Asia',
            'url': 'https://example.com/article/2'
        },
        {
            'title': 'ì¼ë³¸ ì •ë¶€ê¸°ê´€, ëŒ€ê·œëª¨ ì‚¬ì´ë²„ ê³µê²© ë°›ì•„',
            'content': 'ì¼ë³¸ì˜ ì£¼ìš” ì •ë¶€ê¸°ê´€ì´ AI ì‹œìŠ¤í…œì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì ëŒ€ì  ê³µê²©ì„ ë°›ì•˜ë‹¤ê³  ë°œí‘œí–ˆë‹¤.',
            'country': 'ì¼ë³¸',
            'category': 'ë³´ì•ˆ/í•´í‚¹',
            'date': '2025-07-01',
            'sentiment': -0.423,
            'source': 'Nikkei Asia',
            'url': 'https://example.com/article/3'
        },
        {
            'title': 'ë…ì¼, AI ê·œì œ ë²•ì•ˆ ì˜íšŒ í†µê³¼',
            'content': 'ë…ì¼ ì˜íšŒê°€ AI ì‹œìŠ¤í…œì˜ ì•ˆì „ì„±ê³¼ íˆ¬ëª…ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ í¬ê´„ì ì¸ ë²•ì  í”„ë ˆì„ì›Œí¬ë¥¼ í†µê³¼ì‹œì¼°ë‹¤.',
            'country': 'ë…ì¼',
            'category': 'ë²•ë¥ /ê·œì œ',
            'date': '2025-06-30',
            'sentiment': 0.156,
            'source': 'The Next Web',
            'url': 'https://example.com/article/4'
        },
        {
            'title': 'í•œêµ­ ìë™ì°¨ ì—…ì²´, ì™„ì „ììœ¨ì£¼í–‰ ê¸°ìˆ  ì‹œì—°',
            'content': 'í•œêµ­ì˜ ì£¼ìš” ìë™ì°¨ ì œì¡°ì‚¬ê°€ ë§ˆê·¸ë…¸ë‹‰ìŠ¤ ê¸°ìˆ ì„ ì ìš©í•œ ì™„ì „ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œì„ ì„±ê³µì ìœ¼ë¡œ ì‹œì—°í–ˆë‹¤.',
            'country': 'í•œêµ­',
            'category': 'ììœ¨ì‹œìŠ¤í…œ',
            'date': '2025-06-29',
            'sentiment': 0.687,
            'source': 'TechCrunch',
            'url': 'https://example.com/article/5'
        }
    ]
    
    # ì¶”ê°€ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    base_date = datetime.now() - timedelta(days=30)
    
    for i in range(50):
        country = countries[i % len(countries)]
        category = categories[i % len(categories)]
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê°ì • ì ìˆ˜ ì¡°ì •
        if category == "ë³´ì•ˆ/í•´í‚¹":
            sentiment = np.random.normal(-0.2, 0.3)
        elif category == "ë²•ë¥ /ê·œì œ":
            sentiment = np.random.normal(-0.1, 0.4)
        else:
            sentiment = np.random.normal(0.2, 0.3)
        
        sentiment = np.clip(sentiment, -1, 1)
        
        article = {
            'title': f'{country} {category} ê´€ë ¨ ìµœì‹  ê¸°ìˆ  ë‰´ìŠ¤ {i+6}',
            'content': f'ì´ê²ƒì€ {category} ë¶„ì•¼ì˜ {country} ê´€ë ¨ ê¸°ì‚¬ì…ë‹ˆë‹¤. ìµœì‹  ê¸°ìˆ  ë™í–¥ê³¼ ë°œì „ì‚¬í•­ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.',
            'country': country,
            'category': category,
            'date': (base_date + timedelta(days=np.random.randint(0, 30))).strftime('%Y-%m-%d'),
            'sentiment': round(sentiment, 3),
            'source': f'{country} Tech News',
            'url': f'https://example.com/article/{i+6}'
        }
        sample_articles.append(article)
    
    return sample_articles

def create_network_visualization(analyzer):
    """ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” ìƒì„±"""
    if not NETWORKX_AVAILABLE:
        fig = go.Figure()
        fig.add_annotation(
            text="NetworkXê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.<br>ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ pip install networkxë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.",
            xref="paper", yref="paper",
            x=0.5, y=0.5, xanchor='center', yanchor='middle',
            showarrow=False, font=dict(size=16)
        )
        return fig
    
    # ê°„ë‹¨í•œ ê¸°ìˆ  ì—°ê´€ì„± ë„¤íŠ¸ì›Œí¬
    G = nx.Graph()
    categories = list(TECH_CATEGORIES.keys())
    
    # ë…¸ë“œ ì¶”ê°€
    for cat in categories:
        G.add_node(cat)
    
    # ê°„ë‹¨í•œ ì—°ê²° ì¶”ê°€ (ì˜ˆì‹œ)
    connections = [
        ("AI/ML", "ììœ¨ì‹œìŠ¤í…œ"),
        ("í•˜ë“œì›¨ì–´ í˜ì‹ ", "AI/ML"),
        ("ë³´ì•ˆ/í•´í‚¹", "AI/ML"),
        ("ë²•ë¥ /ê·œì œ", "AI/ML"),
        ("ë²•ë¥ /ê·œì œ", "ë³´ì•ˆ/í•´í‚¹")
    ]
    
    for conn in connections:
        G.add_edge(conn[0], conn[1])
    
    # ë ˆì´ì•„ì›ƒ ê³„ì‚°
    pos = nx.spring_layout(G, k=3, iterations=50)
    
    # ì—£ì§€ ê·¸ë¦¬ê¸°
    edge_x = []
    edge_y = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
    
    edge_trace = go.Scatter(x=edge_x, y=edge_y,
                           line=dict(width=2, color='#888'),
                           hoverinfo='none',
                           mode='lines')
    
    # ë…¸ë“œ ê·¸ë¦¬ê¸°
    node_x = []
    node_y = []
    node_text = []
    node_colors = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
        node_colors.append(TECH_CATEGORIES[node]['color'])
    
    node_trace = go.Scatter(x=node_x, y=node_y,
                           mode='markers+text',
                           hoverinfo='text',
                           text=node_text,
                           textposition="middle center",
                           marker=dict(size=30, color=node_colors, line=dict(width=2, color='white')))
    
    fig = go.Figure(data=[edge_trace, node_trace],
                   layout=go.Layout(title='ê¸°ìˆ  ë¶„ì•¼ ê°„ ì—°ê´€ì„± ë„¤íŠ¸ì›Œí¬',
                                   titlefont_size=16,
                                   showlegend=False,
                                   hovermode='closest',
                                   margin=dict(b=20,l=5,r=5,t=40),
                                   annotations=[ dict(
                                       text="ê¸°ìˆ  ë¶„ì•¼ ê°„ ì—°ê´€ì„±ì„ ë³´ì—¬ì£¼ëŠ” ë„¤íŠ¸ì›Œí¬",
                                       showarrow=False,
                                       xref="paper", yref="paper",
                                       x=0.005, y=-0.002 ) ],
                                   xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                   yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))
    
    return fig

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸŒ ê¸€ë¡œë²Œ ê¸°ìˆ  ì´ìŠˆ ë¶„ì„ ì‹œìŠ¤í…œ</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; font-size: 1.2rem; color: #666; margin-bottom: 2rem;">AI ì‹œëŒ€ì˜ ê¸°ìˆ  íŒ¨ëŸ¬ë‹¤ì„ ë³€í™”ì™€ êµ­ì œì  ê±°ë²„ë„ŒìŠ¤ ë™í–¥ ë¶„ì„</p>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("## ğŸ”§ ë¶„ì„ ì„¤ì •")
        
        # ì„±ê³µ ë©”ì‹œì§€
        st.success("ğŸ‰ ë°°í¬ ì„±ê³µ!")
        
        # ê¸°ëŠ¥ ìƒíƒœ í‘œì‹œ
        st.markdown("### ğŸ“Š ê¸°ëŠ¥ ìƒíƒœ")
        st.write(f"âœ… ê¸°ë³¸ ë¶„ì„: ì‚¬ìš© ê°€ëŠ¥")
        st.write(f"{'âœ…' if TEXTBLOB_AVAILABLE else 'âš ï¸'} ê°ì • ë¶„ì„: {'ê³ ê¸‰' if TEXTBLOB_AVAILABLE else 'ê¸°ë³¸'}")
        st.write(f"{'âœ…' if NETWORKX_AVAILABLE else 'âš ï¸'} ë„¤íŠ¸ì›Œí¬ ë¶„ì„: {'ì‚¬ìš© ê°€ëŠ¥' if NETWORKX_AVAILABLE else 'ì œí•œë¨'}")
        st.write(f"{'âœ…' if SKLEARN_AVAILABLE else 'âš ï¸'} ê³ ê¸‰ ë¶„ì„: {'ì‚¬ìš© ê°€ëŠ¥' if SKLEARN_AVAILABLE else 'ì œí•œë¨'}")
        
        st.markdown("---")
        
        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        date_range = st.date_input(
            "ë¶„ì„ ê¸°ê°„",
            value=(datetime.now() - timedelta(days=30), datetime.now()),
            max_value=datetime.now()
        )
        
        # êµ­ê°€ ì„ íƒ
        selected_countries = st.multiselect(
            "ë¶„ì„ ëŒ€ìƒ êµ­ê°€",
            list(COUNTRIES.keys()),
            default=list(COUNTRIES.keys())[:5]
        )
        
        # ê¸°ìˆ  ì¹´í…Œê³ ë¦¬ ì„ íƒ
        selected_categories = st.multiselect(
            "ê¸°ìˆ  ì¹´í…Œê³ ë¦¬",
            list(TECH_CATEGORIES.keys()),
            default=list(TECH_CATEGORIES.keys())
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“Š ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸")
        if st.button("ğŸ”„ ë°ì´í„° ê°±ì‹ "):
            st.rerun()
    
    # ë©”ì¸ ì»¨í…ì¸ 
    with st.spinner("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘..."):
        articles = load_sample_data()
    
    # ë°ì´í„° í•„í„°ë§
    filtered_articles = [
        article for article in articles 
        if article['country'] in selected_countries and article['category'] in selected_categories
    ]
    
    if not filtered_articles:
        st.error("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = TechNewsAnalyzer(filtered_articles)
    
    # ìƒë‹¨ ë©”íŠ¸ë¦­ìŠ¤
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown(
            f'''<div class="metric-card">
                <h4>ğŸ“° ì´ ê¸°ì‚¬ ìˆ˜</h4>
                <h2 style="color: #667eea;">{len(filtered_articles):,}</h2>
                <small>ì„ íƒëœ ì¡°ê±´ì˜ ê¸°ì‚¬</small>
            </div>''',
            unsafe_allow_html=True
        )
    
    with col2:
        unique_countries = len(set(article['country'] for article in filtered_articles))
        st.markdown(
            f'''<div class="metric-card">
                <h4>ğŸŒ ë¶„ì„ êµ­ê°€</h4>
                <h2 style="color: #4ECDC4;">{unique_countries}</h2>
                <small>ê°œ êµ­ê°€</small>
            </div>''',
            unsafe_allow_html=True
        )
    
    with col3:
        unique_categories = len(set(article['category'] for article in filtered_articles))
        st.markdown(
            f'''<div class="metric-card">
                <h4>ğŸ”¬ ê¸°ìˆ  ë¶„ì•¼</h4>
                <h2 style="color: #45B7D1;">{unique_categories}</h2>
                <small>ê°œ ë¶„ì•¼</small>
            </div>''',
            unsafe_allow_html=True
        )
    
    with col4:
        avg_sentiment = np.mean([article['sentiment'] for article in filtered_articles])
        sentiment_emoji = "ğŸ˜Š" if avg_sentiment > 0.1 else "ğŸ˜" if avg_sentiment >= -0.1 else "ğŸ˜Ÿ"
        sentiment_color = "#4CAF50" if avg_sentiment > 0.1 else "#FFC107" if avg_sentiment >= -0.1 else "#F44336"
        st.markdown(
            f'''<div class="metric-card">
                <h4>ğŸ­ ì „ì²´ ê°ì •</h4>
                <h2 style="color: {sentiment_color};">{sentiment_emoji} {avg_sentiment:.3f}</h2>
                <small>ê°ì • ì ìˆ˜</small>
            </div>''',
            unsafe_allow_html=True
        )
    
    with col5:
        latest_date = max(article['date'] for article in filtered_articles)
        st.markdown(
            f'''<div class="metric-card">
                <h4>ğŸ“… ìµœì‹  ì—…ë°ì´íŠ¸</h4>
                <h2 style="color: #96CEB4; font-size: 1.2rem;">{latest_date}</h2>
                <small>ë§ˆì§€ë§‰ ê¸°ì‚¬</small>
            </div>''',
            unsafe_allow_html=True
        )
    
    st.markdown("---")
    
    # íƒ­ ë©”ë‰´
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š ê°œìš” ëŒ€ì‹œë³´ë“œ", 
        "ğŸŒ êµ­ê°€ë³„ ë¶„ì„", 
        "ğŸ”¬ ê¸°ìˆ  íŠ¸ë Œë“œ", 
        "ğŸ•¸ï¸ ì—°ê´€ì„± ë¶„ì„", 
        "ğŸ“° ìµœì‹  ê¸°ì‚¬"
    ])
    
    with tab1:
        st.markdown('<h3 class="sub-header">ğŸ“Š ì „ì²´ í˜„í™© ëŒ€ì‹œë³´ë“œ</h3>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # êµ­ê°€ë³„ ê¸°ì‚¬ ìˆ˜ ë¶„í¬
            country_counts = Counter([article['country'] for article in filtered_articles])
            
            fig_country = px.bar(
                x=list(country_counts.keys()),
                y=list(country_counts.values()),
                title="êµ­ê°€ë³„ ê¸°ìˆ  ì´ìŠˆ ê¸°ì‚¬ ìˆ˜",
                color=list(country_counts.values()),
                color_continuous_scale="viridis",
                text=list(country_counts.values())
            )
            fig_country.update_traces(texttemplate='%{text}', textposition='outside')
            fig_country.update_layout(showlegend=False, height=400)
            st.plotly_chart(fig_country, use_container_width=True)
        
        with col2:
            # ê¸°ìˆ  ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            category_counts = Counter([article['category'] for article in filtered_articles])
            colors = [TECH_CATEGORIES[cat]['color'] for cat in category_counts.keys()]
            
            fig_category = px.pie(
                values=list(category_counts.values()),
                names=list(category_counts.keys()),
                title="ê¸°ìˆ  ë¶„ì•¼ë³„ ê´€ì‹¬ë„",
                color_discrete_sequence=colors
            )
            fig_category.update_traces(textposition='inside', textinfo='percent+label')
            fig_category.update_layout(height=400)
            st.plotly_chart(fig_category, use_container_width=True)
        
        # ì‹œê°„ë³„ íŠ¸ë Œë“œ
        st.markdown('<h4 class="sub-header">ğŸ“ˆ ì‹œê°„ë³„ ì´ìŠˆ ë°œìƒ íŠ¸ë Œë“œ</h4>', unsafe_allow_html=True)
        
        df_articles = pd.DataFrame(filtered_articles)
        df_articles['date'] = pd.to_datetime(df_articles['date'])
        daily_counts = df_articles.groupby(['date', 'category']).size().reset_index(name='count')
        
        colors = [TECH_CATEGORIES[cat]['color'] for cat in TECH_CATEGORIES.keys()]
        
        fig_timeline = px.line(
            daily_counts, 
            x='date', 
            y='count', 
            color='category',
            title="ì¼ë³„ ê¸°ìˆ  ì´ìŠˆ ë°œìƒ íŠ¸ë Œë“œ",
            color_discrete_sequence=colors
        )
        fig_timeline.update_layout(height=500, hovermode='x unified')
        st.plotly_chart(fig_timeline, use_container_width=True)
        
        # ì¸ì‚¬ì´íŠ¸ ë°•ìŠ¤
        insights = analyzer.generate_insights_report()
        st.markdown(
            f'''<div class="insight-box">
                <h4>ğŸ§  ì£¼ìš” ì¸ì‚¬ì´íŠ¸</h4>
                <pre style="white-space: pre-wrap; font-family: inherit; font-size: 0.9rem;">{insights}</pre>
            </div>''',
            unsafe_allow_html=True
        )
    
    with tab2:
        st.markdown('<h3 class="sub-header">ğŸŒ êµ­ê°€ë³„ ê¸°ìˆ  ì´ìŠˆ ë¶„ì„</h3>', unsafe_allow_html=True)
        
        # êµ­ê°€-ê¸°ìˆ  ë§¤íŠ¸ë¦­ìŠ¤
        matrix_data = []
        for country in selected_countries:
            country_articles = [a for a in filtered_articles if a['country'] == country]
            for category in selected_categories:
                category_count = sum(1 for a in country_articles if a['category'] == category)
                matrix_data.append({
                    'country': f"{COUNTRIES.get(country, '')} {country}",
                    'category': category,
                    'count': category_count
                })
        
        if matrix_data:
            matrix_df = pd.DataFrame(matrix_data)
            pivot_matrix = matrix_df.pivot(index='country', columns='category', values='count').fillna(0)
            
            fig_heatmap = px.imshow(
                pivot_matrix.values,
                labels=dict(x="ê¸°ìˆ  ë¶„ì•¼", y="êµ­ê°€", color="ê¸°ì‚¬ ìˆ˜"),
                x=pivot_matrix.columns,
                y=pivot_matrix.index,
                color_continuous_scale="Blues",
                title="êµ­ê°€ë³„ ê¸°ìˆ  ë¶„ì•¼ ì§‘ì¤‘ë„ íˆíŠ¸ë§µ",
                text_auto=True
            )
            fig_heatmap.update_layout(height=600)
            st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # êµ­ê°€ë³„ ê°ì • ë¶„ì„
        col1, col2 = st.columns(2)
        
        with col1:
            country_sentiment = df_articles.groupby('country')['sentiment'].mean().sort_values(ascending=False)
            
            fig_sentiment = px.bar(
                x=country_sentiment.index,
                y=country_sentiment.values,
                title="êµ­ê°€ë³„ í‰ê·  ê°ì • ì ìˆ˜",
                color=country_sentiment.values,
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0
            )
            fig_sentiment.add_hline(y=0, line_dash="dash", line_color="black", annotation_text="ì¤‘ë¦½ì„ ")
            fig_sentiment.update_layout(height=400)
            st.plotly_chart(fig_sentiment, use_container_width=True)
        
        with col2:
            # êµ­ê°€ë³„ ê¸°ìˆ  íŠ¹í™”ë„
            country_focus = analyzer.analyze_country_tech_focus()
            
            st.markdown("### ğŸ¯ êµ­ê°€ë³„ ê¸°ìˆ  íŠ¹í™” ë¶„ì•¼")
            for country, tech_dist in list(country_focus.items())[:5]:
                if tech_dist:
                    top_tech = max(tech_dist, key=tech_dist.get)
                    focus_rate = tech_dist[top_tech]
                    flag = COUNTRIES.get(country, "ğŸ³ï¸")
                    
                    st.markdown(f"**{flag} {country}**")
                    st.markdown(f"íŠ¹í™” ë¶„ì•¼: {top_tech} ({focus_rate:.1%} ì§‘ì¤‘)")
                    
                    # ë¯¸ë‹ˆ ì°¨íŠ¸
                    if len(tech_dist) > 1:
                        tech_names = list(tech_dist.keys())
                        tech_values = list(tech_dist.values())
                        
                        mini_fig = px.pie(
                            values=tech_values,
                            names=tech_names,
                            title=f"{country} ê¸°ìˆ  ë¶„í¬",
                            height=200
                        )
                        mini_fig.update_traces(textposition='inside', textinfo='percent')
                        mini_fig.update_layout(showlegend=False, margin=dict(t=30, b=0, l=0, r=0))
                        st.plotly_chart(mini_fig, use_container_width=True)
                    
                    st.markdown("---")
    
    with tab3:
        st.markdown('<h3 class="sub-header">ğŸ”¬ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„</h3>', unsafe_allow_html=True)
        
        # ì‹ í¥ íŠ¸ë Œë“œ í‚¤ì›Œë“œ
        col1, col2 = st.columns([2, 1])
        
        with col1:
            trending_keywords = analyzer.detect_emerging_trends()
            
            if trending_keywords:
                trend_df = pd.DataFrame([
                    {
                        'keyword': keyword,
                        'trend_score': data['trend_score'],
                        'recent_freq': data['recent_frequency'],
                        'older_freq': data['older_frequency']
                    }
                    for keyword, data in trending_keywords.items()
                ])
                
                fig_trend = px.bar(
                    trend_df,
                    x='trend_score',
                    y='keyword',
                    orientation='h',
                    title="ì‹ í¥ íŠ¸ë Œë“œ í‚¤ì›Œë“œ (ìµœê·¼ 7ì¼ vs ì´ì „ ê¸°ê°„)",
                    color='trend_score',
                    color_continuous_scale="Reds",
                    hover_data=['recent_freq', 'older_freq']
                )
                fig_trend.update_layout(height=400)
                st.plotly_chart(fig_trend, use_container_width=True)
            else:
                st.info("í˜„ì¬ ë°ì´í„°ì—ì„œ ëšœë ·í•œ ì‹ í¥ íŠ¸ë Œë“œë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        with col2:
            st.markdown("### ğŸ“Š íŠ¸ë Œë“œ í•´ì„")
            st.markdown("""
            **íŠ¸ë Œë“œ ì ìˆ˜ í•´ì„:**
            - 2.0x ì´ìƒ: ê¸‰ìƒìŠ¹ íŠ¸ë Œë“œ ğŸ”¥
            - 1.5x - 2.0x: ìƒìŠ¹ íŠ¸ë Œë“œ ğŸ“ˆ
            - 1.0x - 1.5x: ì™„ë§Œí•œ ì¦ê°€ â†—ï¸
            
            **ì£¼ì˜ì‚¬í•­:**
            - ìµœì†Œ 2íšŒ ì´ìƒ ì–¸ê¸‰ëœ í‚¤ì›Œë“œë§Œ í¬í•¨
            - ìµœê·¼ 7ì¼ vs ì´ì „ ê¸°ê°„ ë¹„êµ
            """)
            
            if trending_keywords:
                st.markdown("### ğŸ”¥ í•« í‚¤ì›Œë“œ")
                for keyword, data in list(trending_keywords.items())[:3]:
                    st.markdown(f"**{keyword}**")
                    st.markdown(f"ğŸ“ˆ {data['trend_score']:.1f}x ì¦ê°€")
                    st.markdown("---")
        
        # ê°ì • íŠ¸ë Œë“œ ë¶„ì„
        st.markdown('<h4 class="sub-header">ğŸ­ ê¸°ìˆ  ë¶„ì•¼ë³„ ê°ì • íŠ¸ë Œë“œ</h4>', unsafe_allow_html=True)
        
        category_sentiment = df_articles.groupby('category')['sentiment'].agg(['mean', 'count']).reset_index()
        
        fig_cat_sentiment = px.bar(
            category_sentiment,
            x='category',
            y='mean',
            title="ê¸°ìˆ  ë¶„ì•¼ë³„ í‰ê·  ê°ì • ì ìˆ˜",
            color='mean',
            color_continuous_scale="RdYlGn",
            color_continuous_midpoint=0,
            hover_data=['count']
        )
        fig_cat_sentiment.add_hline(y=0, line_dash="dash", line_color="black")
        st.plotly_chart(fig_cat_sentiment, use_container_width=True)
    
    with tab4:
        st.markdown('<h3 class="sub-header">ğŸ•¸ï¸ ê¸°ìˆ  ê°„ ì—°ê´€ì„± ë„¤íŠ¸ì›Œí¬</h3>', unsafe_allow_html=True)
        
        # ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
        network_fig = create_network_visualization(analyzer)
        st.plotly_chart(network_fig, use_container_width=True)
        
        # ê¸°ìˆ  ì—°ê´€ì„± ì¸ì‚¬ì´íŠ¸
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ”— ê¸°ìˆ  ë¶„ì•¼ ì—°ê´€ì„±")
            st.markdown("""
            **ì£¼ìš” ì—°ê²°ì :**
            - **AI/ML**ì´ ëª¨ë“  ë¶„ì•¼ì˜ ì¤‘ì‹¬
            - **ììœ¨ì‹œìŠ¤í…œ**ì€ AI/MLê³¼ ê°•í•˜ê²Œ ì—°ê²°
            - **ë³´ì•ˆ/í•´í‚¹**ì€ ëª¨ë“  ê¸°ìˆ  ë¶„ì•¼ì— ì˜í–¥
            - **ë²•ë¥ /ê·œì œ**ëŠ” AIì™€ ë³´ì•ˆ ë¶„ì•¼ë¥¼ ì¤‘ì  ë‹¤ë£¸
            """)
        
        with col2:
            st.markdown("### ğŸ“Š ê¸°ìˆ  ìœµí•© íŠ¸ë Œë“œ")
            
            # ê¸°ìˆ  ì¡°í•© ë¶„ì„
            tech_combinations = defaultdict(int)
            for article in filtered_articles:
                title_content = f"{article['title']} {article['content']}".lower()
                mentioned_techs = []
                
                for category, info in TECH_CATEGORIES.items():
                    if any(keyword.lower() in title_content for keyword in info['keywords']):
                        mentioned_techs.append(category)
                
                if len(mentioned_techs) > 1:
                    combo = " + ".join(sorted(mentioned_techs))
                    tech_combinations[combo] += 1
            
            if tech_combinations:
                st.markdown("**ìì£¼ ì–¸ê¸‰ë˜ëŠ” ê¸°ìˆ  ì¡°í•©:**")
                for combo, count in sorted(tech_combinations.items(), key=lambda x: x[1], reverse=True)[:5]:
                    st.markdown(f"- {combo}: {count}íšŒ")
            else:
                st.markdown("ê¸°ìˆ  ìœµí•© ì‚¬ë¡€ë¥¼ ë” ë¶„ì„í•˜ë ¤ë©´ ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    with tab5:
        st.markdown('<h3 class="sub-header">ğŸ“° ìµœì‹  ê¸°ìˆ  ì´ìŠˆ í”¼ë“œ</h3>', unsafe_allow_html=True)
        
        # ìµœì‹  ê¸°ì‚¬ ëª©ë¡
        latest_articles = sorted(filtered_articles, key=lambda x: x['date'], reverse=True)[:10]
        
        for i, article in enumerate(latest_articles):
            with st.expander(f"ğŸ“„ {article['title']}", expanded=(i < 2)):
                col1, col2, col3 = st.columns([3, 1, 1])
                
                with col1:
                    st.write(article['content'])
                    st.markdown(f"ğŸ”— [ì›ë¬¸ ë³´ê¸°]({article['url']})")
                
                with col2:
                    # ì¹´í…Œê³ ë¦¬ ë°°ì§€
                    color = TECH_CATEGORIES.get(article['category'], {}).get('color', '#888888')
                    st.markdown(
                        f'<span class="tech-category" style="background-color: {color}">{article["category"]}</span>',
                        unsafe_allow_html=True
                    )
                    
                    flag = COUNTRIES.get(article['country'], "ğŸ³ï¸")
                    st.write(f"**ğŸŒ êµ­ê°€:** {flag} {article['country']}")
                    st.write(f"**ğŸ“… ë‚ ì§œ:** {article['date']}")
                    st.write(f"**ğŸ“° ì¶œì²˜:** {article['source']}")
                
                with col3:
                    # ê°ì • ë¶„ì„ ê²°ê³¼
                    sentiment = article['sentiment']
                    if sentiment > 0.1:
                        sentiment_emoji = "ğŸ˜Š"
                        sentiment_color = "#4CAF50"
                        sentiment_text = "ê¸ì •ì "
                    elif sentiment < -0.1:
                        sentiment_emoji = "ğŸ˜Ÿ"
                        sentiment_color = "#F44336"
                        sentiment_text = "ë¶€ì •ì "
                    else:
                        sentiment_emoji = "ğŸ˜"
                        sentiment_color = "#FFC107"
                        sentiment_text = "ì¤‘ë¦½ì "
                    
                    st.markdown(f"**ğŸ­ ê°ì • ë¶„ì„**")
                    st.markdown(
                        f'<div style="text-align: center; color: {sentiment_color};">'
                        f'<div style="font-size: 2rem;">{sentiment_emoji}</div>'
                        f'<div>{sentiment_text}</div>'
                        f'<div style="font-size: 0.9rem;">({sentiment:.3f})</div>'
                        f'</div>',
                        unsafe_allow_html=True
                    )
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        f'''<div class="data-source">
            <p>ğŸ“Š <strong>ë°ì´í„° í˜„í™©:</strong> ìƒ˜í”Œ ë°ì´í„° | 
            ğŸ”„ <strong>ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:</strong> {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} | 
            ğŸ“ˆ <strong>ë¶„ì„ ê¸°ì‚¬ ìˆ˜:</strong> {len(filtered_articles):,}ê°œ</p>
        </div>''',
        unsafe_allow_html=True
    )
    
    st.markdown(
        """
        <div style="text-align: center; color: #666; padding: 2rem; background: #f8f9fa; border-radius: 10px; margin-top: 2rem;">
            <h4>ğŸ”¬ êµ­ì œ ì‹œì‚¬ íƒêµ¬ ë™ì•„ë¦¬ - ê¸€ë¡œë²Œ ê¸°ìˆ  ì´ìŠˆ ë¶„ì„ í”„ë¡œì íŠ¸</h4>
            <p>Streamlit Cloud ë…ë¦½í˜• ë²„ì „ | ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ê³¼ ë¯¸ë˜ ê¸°ìˆ  íŠ¸ë Œë“œ ì˜ˆì¸¡</p>
            <p><small>ğŸ‰ ì„±ê³µì ìœ¼ë¡œ ë°°í¬ë˜ì—ˆìŠµë‹ˆë‹¤! Made with â¤ï¸ using Streamlit & Python</small></p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
